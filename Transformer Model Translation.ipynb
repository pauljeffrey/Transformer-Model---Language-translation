{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer Model Translation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOO4jG4RJN9GWYAVLUO7B+x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c216c04ef74148c98ed7c7f25e0bdab5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_078c2efc457d46b2be76e14ce7e71f7b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2f94e00735ac43a0992d24f630daccf5","IPY_MODEL_c7f827ae9484401a819024869e632e6e"]}},"078c2efc457d46b2be76e14ce7e71f7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f94e00735ac43a0992d24f630daccf5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_41986581bd22478190b0ac3efe0e8576","_dom_classes":[],"description":"Dl Completed...: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_47ef4cb80f864215bbbcb976b13d18c0"}},"c7f827ae9484401a819024869e632e6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e0e7a33ed6784f75ac51369dee8ebbd0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:07&lt;00:00,  7.29s/ url]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f1e5630b83d142b9821803328440af0c"}},"41986581bd22478190b0ac3efe0e8576":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"47ef4cb80f864215bbbcb976b13d18c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0e7a33ed6784f75ac51369dee8ebbd0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f1e5630b83d142b9821803328440af0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec0bff210d624fb88ecd40069177dd5a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_be7eece35ae84cbbbfc2bd966f05c5e8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_60ff60f1f4204fd7b4f32a186d238cc8","IPY_MODEL_63d023279f9d413b81cc3fcaa4dee65c"]}},"be7eece35ae84cbbbfc2bd966f05c5e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60ff60f1f4204fd7b4f32a186d238cc8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9a6095937df94b1da402d4ed90fcb36e","_dom_classes":[],"description":"Dl Size...: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd8df5f477ec492e91c8efb1c41a992f"}},"63d023279f9d413b81cc3fcaa4dee65c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_91efed0c469542a1b534b448a7c16ac9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 124/124 [00:07&lt;00:00, 17.09 MiB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f5aecd019d9247048565cadf178869b0"}},"9a6095937df94b1da402d4ed90fcb36e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bd8df5f477ec492e91c8efb1c41a992f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91efed0c469542a1b534b448a7c16ac9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f5aecd019d9247048565cadf178869b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2699af0d679d42cb9b37c2e8830f613a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bdd1d2f89def4349ad5027cf5505b28d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7b2d0f4a27da44a6bbb6bbc2eb019e65","IPY_MODEL_0134613c4d8e4a0e864701eb13971b0c"]}},"bdd1d2f89def4349ad5027cf5505b28d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b2d0f4a27da44a6bbb6bbc2eb019e65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_69d34dd33d5d40b9a150e7925cf13d3a","_dom_classes":[],"description":"Extraction completed...: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_616793e04b66413d80207097aecccdfe"}},"0134613c4d8e4a0e864701eb13971b0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4b836b8e91cf434f84766e97038a98f3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:07&lt;00:00,  7.22s/ file]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2a7a31d72fbb43ad8868f3d0821e7fba"}},"69d34dd33d5d40b9a150e7925cf13d3a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"616793e04b66413d80207097aecccdfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4b836b8e91cf434f84766e97038a98f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2a7a31d72fbb43ad8868f3d0821e7fba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af72bd33b9004812a04db350ebe8c279":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_20bc7cac39174c91a18fc1791bbca695","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d2955606a7a0468b8a3814356dbe6859","IPY_MODEL_285157fd52154ec08d2be07d387daeca"]}},"20bc7cac39174c91a18fc1791bbca695":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d2955606a7a0468b8a3814356dbe6859":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_272f6fed16c04695a2aff1dc3bbf9643","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3df2341cb735418494b26d563742e3c8"}},"285157fd52154ec08d2be07d387daeca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fd6916fb7a174c1691553d1cab990066","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 51785/0 [00:08&lt;00:00, 6236.76 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68635e4813a84e13aeb50d02a3f18e06"}},"272f6fed16c04695a2aff1dc3bbf9643":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3df2341cb735418494b26d563742e3c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd6916fb7a174c1691553d1cab990066":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"68635e4813a84e13aeb50d02a3f18e06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"757e0721f88c4d13898dcc03c06967eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9c4621fc3a1048619ab9695aef8a507d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_973adc858214401ea250f1c038c707a7","IPY_MODEL_f26b516a7aff462e9293313f30cb0dfa"]}},"9c4621fc3a1048619ab9695aef8a507d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"973adc858214401ea250f1c038c707a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a6992c1d4e5044d2a75a80d178216388","_dom_classes":[],"description":" 66%","_model_name":"FloatProgressModel","bar_style":"danger","max":51785,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":34010,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_509e6f14410540c79e3378a4c17aca30"}},"f26b516a7aff462e9293313f30cb0dfa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9fd7d81d18b941c39dc1af70d7b40758","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 34010/51785 [00:00&lt;25:55, 11.43 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a6f24bc26574bf4becaecd371be1b47"}},"a6992c1d4e5044d2a75a80d178216388":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"509e6f14410540c79e3378a4c17aca30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fd7d81d18b941c39dc1af70d7b40758":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3a6f24bc26574bf4becaecd371be1b47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e982213b6e347caaa39971ea8487426":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7a94656865554e91b8ca15cfe3062e7c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_581675c432bb4f378ce350390ee389b4","IPY_MODEL_1458406ef512425893f85d1ffbab6c85"]}},"7a94656865554e91b8ca15cfe3062e7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"581675c432bb4f378ce350390ee389b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d874c7a575074f5082dded3181b9ee30","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_491d1a6323184996b231b32b7f588208"}},"1458406ef512425893f85d1ffbab6c85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_93e5be2d1a4541c7bdaa5b91c2761087","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1193/0 [00:00&lt;00:00, 2393.20 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c621fe536aeb47fdbfc26ca0e575b70b"}},"d874c7a575074f5082dded3181b9ee30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"491d1a6323184996b231b32b7f588208":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"93e5be2d1a4541c7bdaa5b91c2761087":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c621fe536aeb47fdbfc26ca0e575b70b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13c8c19193f94c6099b6beabee8302ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_968831fef12641e3ba1bef489df1eb21","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_da66903a32324ce4acfd8a836de0ee70","IPY_MODEL_182bbd2550d64717b0545d90f22754ab"]}},"968831fef12641e3ba1bef489df1eb21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da66903a32324ce4acfd8a836de0ee70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5cbce51071504b63a28c70f1a6f96607","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"danger","max":1193,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8abcd2b5665f442ea3d6cd779c9cb9cd"}},"182bbd2550d64717b0545d90f22754ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_518598c847664152be3be12cbcc0d950","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/1193 [00:00&lt;?, ? examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89a879c7bf1e48aa8b3e24e9366a5d43"}},"5cbce51071504b63a28c70f1a6f96607":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8abcd2b5665f442ea3d6cd779c9cb9cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"518598c847664152be3be12cbcc0d950":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"89a879c7bf1e48aa8b3e24e9366a5d43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ae166b1f367a43f091acba7cf0d59002":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_424a5f22b1ec4503927d73606875fd29","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aaf27d362b7d4bfeba378ec1170f4311","IPY_MODEL_92a4f39eb0f44ec7adbbbac6c1fec4d0"]}},"424a5f22b1ec4503927d73606875fd29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aaf27d362b7d4bfeba378ec1170f4311":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a877975064f84f629b04a40c711322e7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5132076cd59844dbbc187c3d30e22df7"}},"92a4f39eb0f44ec7adbbbac6c1fec4d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_438d67a6c55d48369036ed679e0ef0a5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1803/0 [00:00&lt;00:00, 1114.92 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c08d34c541f34f5aa0f0ab1723ac3e9e"}},"a877975064f84f629b04a40c711322e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5132076cd59844dbbc187c3d30e22df7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"438d67a6c55d48369036ed679e0ef0a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c08d34c541f34f5aa0f0ab1723ac3e9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ce382f2be5c41608ea1fa93bbbdf849":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a63b3400d40c4131b0104ca729a92ea7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9376d4edd72940729e3c4ee1d0cccf3a","IPY_MODEL_cda043a0d57441618b143f46ff658393"]}},"a63b3400d40c4131b0104ca729a92ea7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9376d4edd72940729e3c4ee1d0cccf3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f25086c60cb04586bed2b2a9c909e84c","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"danger","max":1803,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db7f6decfb8e4125bb794e13321a6b8b"}},"cda043a0d57441618b143f46ff658393":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_84f62209183c4adfbb39adb2a85f3c7f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/1803 [00:00&lt;?, ? examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c25dc33fb6af41bb95ea747f7915f698"}},"f25086c60cb04586bed2b2a9c909e84c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"db7f6decfb8e4125bb794e13321a6b8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"84f62209183c4adfbb39adb2a85f3c7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c25dc33fb6af41bb95ea747f7915f698":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BoAUTJilcSbI","executionInfo":{"status":"ok","timestamp":1613781732777,"user_tz":-60,"elapsed":8528,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"14301c59-1302-4237-8180-1d9c0e4e2acd"},"source":["%pip install -q tensorflow_datasets\r\n","% pip install -q tensorflow_text"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 3.4MB 5.9MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rok2HqLFeY9S"},"source":["import collections\r\n","import logging\r\n","import os\r\n","import pathlib\r\n","import re\r\n","import string\r\n","import sys\r\n","import time\r\n","\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","\r\n","import tensorflow_datasets as tfds\r\n","import tensorflow_text as text\r\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yWvFIeF-fM7F"},"source":["logging.getLogger('tensorflow').setLevel(logging.ERROR) # suppress warnings"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416,"referenced_widgets":["c216c04ef74148c98ed7c7f25e0bdab5","078c2efc457d46b2be76e14ce7e71f7b","2f94e00735ac43a0992d24f630daccf5","c7f827ae9484401a819024869e632e6e","41986581bd22478190b0ac3efe0e8576","47ef4cb80f864215bbbcb976b13d18c0","e0e7a33ed6784f75ac51369dee8ebbd0","f1e5630b83d142b9821803328440af0c","ec0bff210d624fb88ecd40069177dd5a","be7eece35ae84cbbbfc2bd966f05c5e8","60ff60f1f4204fd7b4f32a186d238cc8","63d023279f9d413b81cc3fcaa4dee65c","9a6095937df94b1da402d4ed90fcb36e","bd8df5f477ec492e91c8efb1c41a992f","91efed0c469542a1b534b448a7c16ac9","f5aecd019d9247048565cadf178869b0","2699af0d679d42cb9b37c2e8830f613a","bdd1d2f89def4349ad5027cf5505b28d","7b2d0f4a27da44a6bbb6bbc2eb019e65","0134613c4d8e4a0e864701eb13971b0c","69d34dd33d5d40b9a150e7925cf13d3a","616793e04b66413d80207097aecccdfe","4b836b8e91cf434f84766e97038a98f3","2a7a31d72fbb43ad8868f3d0821e7fba","af72bd33b9004812a04db350ebe8c279","20bc7cac39174c91a18fc1791bbca695","d2955606a7a0468b8a3814356dbe6859","285157fd52154ec08d2be07d387daeca","272f6fed16c04695a2aff1dc3bbf9643","3df2341cb735418494b26d563742e3c8","fd6916fb7a174c1691553d1cab990066","68635e4813a84e13aeb50d02a3f18e06","757e0721f88c4d13898dcc03c06967eb","9c4621fc3a1048619ab9695aef8a507d","973adc858214401ea250f1c038c707a7","f26b516a7aff462e9293313f30cb0dfa","a6992c1d4e5044d2a75a80d178216388","509e6f14410540c79e3378a4c17aca30","9fd7d81d18b941c39dc1af70d7b40758","3a6f24bc26574bf4becaecd371be1b47","6e982213b6e347caaa39971ea8487426","7a94656865554e91b8ca15cfe3062e7c","581675c432bb4f378ce350390ee389b4","1458406ef512425893f85d1ffbab6c85","d874c7a575074f5082dded3181b9ee30","491d1a6323184996b231b32b7f588208","93e5be2d1a4541c7bdaa5b91c2761087","c621fe536aeb47fdbfc26ca0e575b70b","13c8c19193f94c6099b6beabee8302ce","968831fef12641e3ba1bef489df1eb21","da66903a32324ce4acfd8a836de0ee70","182bbd2550d64717b0545d90f22754ab","5cbce51071504b63a28c70f1a6f96607","8abcd2b5665f442ea3d6cd779c9cb9cd","518598c847664152be3be12cbcc0d950","89a879c7bf1e48aa8b3e24e9366a5d43","ae166b1f367a43f091acba7cf0d59002","424a5f22b1ec4503927d73606875fd29","aaf27d362b7d4bfeba378ec1170f4311","92a4f39eb0f44ec7adbbbac6c1fec4d0","a877975064f84f629b04a40c711322e7","5132076cd59844dbbc187c3d30e22df7","438d67a6c55d48369036ed679e0ef0a5","c08d34c541f34f5aa0f0ab1723ac3e9e","5ce382f2be5c41608ea1fa93bbbdf849","a63b3400d40c4131b0104ca729a92ea7","9376d4edd72940729e3c4ee1d0cccf3a","cda043a0d57441618b143f46ff658393","f25086c60cb04586bed2b2a9c909e84c","db7f6decfb8e4125bb794e13321a6b8b","84f62209183c4adfbb39adb2a85f3c7f","c25dc33fb6af41bb95ea747f7915f698"]},"id":"Aio-qIphflEL","executionInfo":{"status":"ok","timestamp":1613781754047,"user_tz":-60,"elapsed":29699,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"db87ca05-7b77-4ff9-920c-e8a92c79c721"},"source":["# Download dataset\r\n","examples , metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\r\n","train_examples, val_examples = examples['train'] ,examples['validation']\r\n","\r\n","# returns a tf.data.Dataset object that yields pairs of text examples."],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1mDownloading and preparing dataset ted_hrlr_translate/pt_to_en/1.0.0 (download: 124.94 MiB, generated: Unknown size, total: 124.94 MiB) to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0...\u001b[0m\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c216c04ef74148c98ed7c7f25e0bdab5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec0bff210d624fb88ecd40069177dd5a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2699af0d679d42cb9b37c2e8830f613a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af72bd33b9004812a04db350ebe8c279","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\rShuffling and writing examples to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incompletePPVAEA/ted_hrlr_translate-train.tfrecord\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"757e0721f88c4d13898dcc03c06967eb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=51785.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e982213b6e347caaa39971ea8487426","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\rShuffling and writing examples to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incompletePPVAEA/ted_hrlr_translate-validation.tfrecord\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13c8c19193f94c6099b6beabee8302ce","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1193.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae166b1f367a43f091acba7cf0d59002","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\rShuffling and writing examples to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incompletePPVAEA/ted_hrlr_translate-test.tfrecord\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ce382f2be5c41608ea1fa93bbbdf849","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1803.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\u001b[1mDataset ted_hrlr_translate downloaded and prepared to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n","\r"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"-i9a9EUug2yx","executionInfo":{"status":"ok","timestamp":1613781754060,"user_tz":-60,"elapsed":29684,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"8bba021f-1c39-452c-cb92-02d32f28d694"},"source":["# Download and unzip and impoort the subword tokenizer optimized for this dataset.\r\n","model_name = \"ted_hrlr_translate_pt_en_converter\"\r\n","tf.keras.utils.get_file(\r\n","    f\"{model_name}.zip\",\r\n","    f\"https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip\",\r\n","    cache_dir='.', cache_subdir='', extract=True\r\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/models/ted_hrlr_translate_pt_en_converter.zip\n","188416/184801 [==============================] - 0s 0us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./ted_hrlr_translate_pt_en_converter.zip'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"jxRq2aGOhxSN"},"source":["tokenizers = tf.saved_model.load(model_name) # Loads the tokenizer that was specifically optiimized for this portugese - english dataset."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBW0YKF5iBtH","executionInfo":{"status":"ok","timestamp":1613781756006,"user_tz":-60,"elapsed":31599,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"bb311678-67c5-4609-be5f-bc77eb15273d"},"source":["[item for item in dir(tokenizers.en) if not item.startswith('_')]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['detokenize',\n"," 'get_reserved_tokens',\n"," 'get_vocab_path',\n"," 'get_vocab_size',\n"," 'lookup',\n"," 'tokenize',\n"," 'tokenizer',\n"," 'vocab']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"CE_ovifXiJ65"},"source":["# Function encodes the batches of raw text\r\n","\r\n","def tokenize_pairs(pt, en):\r\n","  pt = tokenizers.pt.tokenize(pt)\r\n","  # Convert from ragged to dense, padding with zeros.\r\n","  pt  = pt.to_tensor()\r\n","\r\n","  en = tokenizers.en.tokenize(en)\r\n","  en = en.to_tensor()\r\n","  return pt, en\r\n","\r\n","\r\n","# Pipeline that processes, shuffles and batches data\r\n","BUFFER_SIZE = 20000\r\n","BATCH_SIZE = 64\r\n","\r\n","def make_batches(ds):\r\n","  return (ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).map(tokenize_pairs, num_parallel_calls= tf.data.AUTOTUNE)\r\n","  .prefetch(tf.data.AUTOTUNE))\r\n","\r\n","train_batches = make_batches(train_examples)\r\n","val_batches = make_batches(val_examples) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n3Bk9J759Nx2","executionInfo":{"status":"ok","timestamp":1613781756010,"user_tz":-60,"elapsed":31578,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"eca71554-f723-4ec7-cdd7-370d25de933d"},"source":["def get_angles(pos, i, d_model):\r\n","  angle_rates  = 1 / np.power(10000, (2 * (i // 2) / np.float32(d_model)))\r\n","  return pos * angle_rates\r\n","\r\n","\r\n","def positional_encoding(position, d_model):\r\n","  angle_rads = get_angles( np.arange(position)[:,np.newaxis], np.arange(d_model)[np.newaxis,:], d_model)\r\n","\r\n","  #apply sin to even indices in the array ; 2i\r\n","  angle_rads[:, 0::2]   = np.sin(angle_rads[:, 0::2])\r\n","\r\n","  # apply cos to odd indices in the array; 2i + 1\r\n","  angle_rads[:, 1::2]   = np.cos(angle_rads[:, 1:: 2])\r\n","\r\n","  pos_encoding = angle_rads[np.newaxis, ...]\r\n","\r\n","  return tf.cast(pos_encoding, dtype= tf.float32)\r\n","\r\n","#get_angles(np.arange(5)[:, np.newaxis], np.arange(3)[np.newaxis,:],3)\r\n","pos = positional_encoding(5,3)\r\n","print(pos.shape)\r\n","print(pos)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1, 5, 3)\n","tf.Tensor(\n","[[[ 0.          1.          0.        ]\n","  [ 0.84147096  0.5403023   0.00215443]\n","  [ 0.9092974  -0.41614684  0.00430886]\n","  [ 0.14112    -0.9899925   0.00646326]\n","  [-0.7568025  -0.6536436   0.00861763]]], shape=(1, 5, 3), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r16WPf-h_dzz","executionInfo":{"status":"ok","timestamp":1613781756013,"user_tz":-60,"elapsed":31561,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"28fce5c4-4ce9-44a6-9cc3-221d71591429"},"source":["# Masking : outputs a 1 at locations of padding and 0 otherwise\r\n","\r\n","\r\n","def create_padding_mask(seq):\r\n","  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\r\n","\r\n","  # add extra dimensions to add the padding to the attention logits.\r\n","  return seq[:, tf.newaxis, tf.newaxis, :] # (batch_size, 1, 1, seq_len)\r\n","\r\n","\r\n","def create_look_ahead_mask(size):\r\n","  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\r\n","  return mask # (seq_len , seq_len)\r\n","\r\n","create_look_ahead_mask(8)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(8, 8), dtype=float32, numpy=\n","array([[0., 1., 1., 1., 1., 1., 1., 1.],\n","       [0., 0., 1., 1., 1., 1., 1., 1.],\n","       [0., 0., 0., 1., 1., 1., 1., 1.],\n","       [0., 0., 0., 0., 1., 1., 1., 1.],\n","       [0., 0., 0., 0., 0., 1., 1., 1.],\n","       [0., 0., 0., 0., 0., 0., 1., 1.],\n","       [0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5BcBwSWVx31","executionInfo":{"status":"ok","timestamp":1613781756015,"user_tz":-60,"elapsed":31540,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"a3137d46-a1d3-4b20-e597-a62fd92f33a5"},"source":["x = tf.random.uniform((3,4,4), minval=1 , maxval =3, dtype = tf.float32)\r\n","z = tf.random.uniform((3,1,1,4), minval=0, maxval=3, dtype=tf.float32)\r\n","\r\n","(x+ z).shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([3, 3, 4, 4])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"Xe5OrIdaNzEC"},"source":["# Scaled dot product attention\r\n","\r\n","def scaled_dot_product_attention(q, k, v, mask):\r\n","  \"\"\"Calculate the attention weights.\r\n","  q, k, v must have matching leading dimensions.\r\n","  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\r\n","  The mask has different shapes depending on its type(padding or look ahead) \r\n","  but it must be broadcastable for addition.\r\n","\r\n","  Args:\r\n","    q: query shape == (..., seq_len_q, depth)\r\n","    k: key shape == (..., seq_len_k, depth)\r\n","    v: value shape == (..., seq_len_v, depth_v)\r\n","    mask: Float tensor with shape broadcastable \r\n","          to (..., seq_len_q, seq_len_k). Defaults to None.\r\n","\r\n","  Returns:\r\n","    output, attention_weights\r\n","  \"\"\"\r\n","  matmul_qk = tf.matmul( q, k, transpose_b=True) # (...., seq_len_q, seq_len_k)\r\n","\r\n","  # scale matmul_qk\r\n","  dk = tf.cast(tf.shape(k)[-1], tf.float32)\r\n","  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\r\n","\r\n","  # add the mask to the scaled tensor.\r\n","  if mask is not None:\r\n","    scaled_attention_logits += (mask * -1e9)\r\n","\r\n","  # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\r\n","  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) # (..., seq_len_q ,seq_len_k)\r\n","\r\n","  output  = tf.matmul(attention_weights, v) # (..., seq_len_q, depth_v)\r\n","\r\n","  return output, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvzLChE0bRls"},"source":["# Multi-head Attention\r\n","class MultiHeadAttention(tf.keras.layers.Layer):\r\n","  def __init__(self, d_model, num_heads):\r\n","    super(MultiHeadAttention, self).__init__()\r\n","    self.num_heads = num_heads\r\n","    self.d_model = d_model\r\n","\r\n","    assert d_model % self.num_heads == 0\r\n","\r\n","    self.depth = d_model // self.num_heads\r\n","\r\n","    self.wq = tf.keras.layers.Dense(d_model)\r\n","    self.wk = tf.keras.layers.Dense(d_model)\r\n","    self.wv = tf.keras.layers.Dense(d_model)\r\n","\r\n","    self.dense = tf.keras.layers.Dense(d_model)\r\n","\r\n","  def split_heads(self, x, batch_size):\r\n","    \"\"\"Split the last dimension into (num_heads, depth).\r\n","    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\r\n","    \"\"\"\r\n","    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\r\n","    return tf.transpose(x, perm=[0, 2, 1, 3])\r\n","\r\n","  def call(self, v, k, q, mask):\r\n","    batch_size = tf.shape(q)[0]\r\n","\r\n","    q = self.wq(q)  # (batch_size, seq_len, d_model)\r\n","    k = self.wk(k)  # (batch_size, seq_len, d_model)\r\n","    v = self.wv(v)  # (batch_size, seq_len, d_model)\r\n","\r\n","    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\r\n","    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\r\n","    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\r\n","\r\n","    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\r\n","    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\r\n","    scaled_attention, attention_weights = scaled_dot_product_attention(\r\n","        q, k, v, mask)\r\n","\r\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\r\n","\r\n","    concat_attention = tf.reshape(scaled_attention, \r\n","                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\r\n","\r\n","    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\r\n","\r\n","    return output, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CiLZkVa5qzvY","executionInfo":{"status":"ok","timestamp":1613781756638,"user_tz":-60,"elapsed":32122,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"3628dec0-db42-4b42-97b7-aa1f2fd2fd24"},"source":["temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\r\n","y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\r\n","out, attn = temp_mha(y, k=y, q=y, mask=None)\r\n","out.shape, attn.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"4Al5Jt4LrtZT"},"source":["# Point wise feed forward network\r\n","def point_wise_feed_forward_network(d_model, dff):\r\n","  return tf.keras.Sequential([\r\n","                              tf.keras.layers.Dense(dff, activation='relu'), #(batch_size, seq_len, dff)\r\n","                              tf.keras.layers.Dense(d_model) # (batch_size, seq_len, d_model)\r\n","                  ])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8LPSDi6JvX7o"},"source":["Encoder and Decoder"]},{"cell_type":"code","metadata":{"id":"pxo3wrD8vdMo"},"source":["# Encoder Layer\r\n","class EncoderLayer(tf.keras.layers.Layer):\r\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\r\n","    super(EncoderLayer, self).__init__()\r\n","\r\n","    self.mha = MultiHeadAttention(d_model, num_heads)\r\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\r\n","\r\n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\r\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\r\n","\r\n","    self.dropout1 = tf.keras.layers.Dropout(rate)\r\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\r\n","\r\n","\r\n","  def call(self, x, training, mask):\r\n","    attn_output, _ = self.mha(x,x,x,mask) # (batch_size, input_seq_len, d_model)\r\n","\r\n","    attn_output = self.dropout1(attn_output, training= training)\r\n","    out1 = self.layernorm1(x + attn_output)   # (batch_size, input_seq_len, d_model)\r\n","\r\n","    ffn_output = self.ffn(out1) # (batch_size, input_seq_len, d_model)\r\n","    ffn_output = self.dropout2(ffn_output, training = training)\r\n","    out2 = self.layernorm2(out1 + ffn_output) # (batch_size, input_seq_len, d_model)\r\n","\r\n","\r\n","    return out2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TGFPTpgq1soF","executionInfo":{"status":"ok","timestamp":1613781756642,"user_tz":-60,"elapsed":32094,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"ee4cdd6d-a926-4d21-e40a-4611775dcf22"},"source":["sample_encoder_layer = EncoderLayer(512, 8, 2048)\r\n","\r\n","sample_encoder_layer_output = sample_encoder_layer(\r\n","    tf.random.uniform((64, 43, 512)), False, None)\r\n","\r\n","sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 43, 512])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"3Gw3294i1wjE"},"source":["# Decoder layer\r\n","\r\n","# Masked multi-head attention sublayer (with look ahead mask and padding mask)\r\n","# Multi-head atttention (with padding mask). V and K receive the encoder output as inputs. Q receives the output from the masked\r\n","# multihead attention sublayer.\r\n","# Point wise feed forward network\r\n","\r\n","class DecoderLayer(tf.keras.layers.Layer):\r\n","  def __init__(self, d_model, num_heads, dff , rate=0.1):\r\n","    super(DecoderLayer, self).__init__()\r\n","\r\n","\r\n","    self.mha1 = MultiHeadAttention(d_model, num_heads)\r\n","    self.mha2 = MultiHeadAttention(d_model, num_heads)\r\n","\r\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\r\n","\r\n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\r\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\r\n","    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\r\n","\r\n","    self.dropout1 = tf.keras.layers.Dropout(rate)\r\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\r\n","    self.dropout3 = tf.keras.layers.Dropout(rate)\r\n","\r\n","  def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\r\n","    # enc_output.shape == (batch_size, input_seq_len, d_model)\r\n","\r\n","    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask) # (batch_size, target_seq_len, d_model)\r\n","    attn1 = self.dropout1(attn1, training=training)\r\n","    out1 = self.layernorm1(attn1 + x)\r\n","\r\n","    attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask) # (batch_size, target_seq_len, d_model)\r\n","    attn2 = self.dropout2(attn2, training= training)\r\n","    out2 = self.layernorm2(attn2 + out1) # (batch_size, target_seq_len, d_model)\r\n","\r\n","    ffn_output = self.ffn(out2) # (batch_size, target_seq_len, d_model)\r\n","    ffn_output = self.dropout3(ffn_output, training = training)\r\n","    out3 = self.layernorm3(ffn_output + out2) # (batch_size, target_seq_len, d_Model)\r\n","\r\n","    return out3, attn_weights_block1, attn_weights_block2\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKQkzhxa7opt","executionInfo":{"status":"ok","timestamp":1613781757783,"user_tz":-60,"elapsed":33209,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"6d220541-0b1a-4ae5-9eb4-16c6ba03b12b"},"source":["sample_decoder_layer = DecoderLayer(512, 8, 2048)\r\n","\r\n","sample_decoder_layer_output, _, _ = sample_decoder_layer(\r\n","    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \r\n","    False, None, None)\r\n","\r\n","sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 50, 512])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"j_79o1W58J9V"},"source":["# Encoder consists of : \r\n","# Input embedding\r\n","# Positional Encoding\r\n","# N encoder layers\r\n","\r\n","class Encoder(tf.keras.layers.Layer):\r\n","  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\r\n","    super(Encoder, self).__init__()\r\n","\r\n","    self.d_model = d_model\r\n","    self.num_layers = num_layers\r\n","\r\n","    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\r\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\r\n","\r\n","    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\r\n","\r\n","    self.dropout = tf.keras.layers.Dropout(rate)\r\n","\r\n","  def call(self, x , training , mask):\r\n","\r\n","    seq_len = tf.shape(x)[1]\r\n","\r\n","    # adding embedding and position encoding\r\n","    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\r\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\r\n","    x += self.pos_encoding[:, : seq_len: ]\r\n","\r\n","    x = self.dropout(x , training =training)\r\n","\r\n","    for i in  range(self.num_layers):\r\n","      x = self.enc_layers[i](x, training, mask)\r\n","\r\n","    return x #(batch_size, input_seq_len, d_model)\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3iUDgdhw_WSH"},"source":["# Decoder\r\n","\r\n","# Output embedding\r\n","# positional encoding\r\n","# N decoder layers\r\n","\r\n","# The output of this decoder is the input to the final FC layer\r\n","\r\n","class Decoder(tf.keras.layers.Layer):\r\n","  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\r\n","    super(Decoder, self).__init__()\r\n","\r\n","    self.d_model = d_model\r\n","    self.num_layers  = num_layers\r\n","\r\n","    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\r\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\r\n","\r\n","    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\r\n","\r\n","    self.dropout  = tf.keras.layers.Dropout(rate)\r\n","\r\n","  def call(self, x ,enc_output, training, look_ahead_mask, padding_mask):\r\n","    seq_len = tf.shape(x)[1]\r\n","    attention_weights = {}\r\n","\r\n","    x = self.embedding(x) # (batch_size, target_seq_len, d_model)\r\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\r\n","\r\n","    x += self.pos_encoding[:, :seq_len, : ]\r\n","\r\n","    x  = self.dropout(x, training=training)\r\n","\r\n","    for i in range(self.num_layers):\r\n","      x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\r\n","\r\n","      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\r\n","      attention_weights[ 'decoder_layer{}_block2'.format(i+1)] = block2\r\n","\r\n","    # x.shape == (batch_size, target_seq_len, d_model)\r\n","    return x , attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-UM9p-qGCl4a"},"source":["# Create Transformer\r\n","\r\n","class Transformer(tf.keras.Model):\r\n","  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \r\n","               target_vocab_size, pe_input, pe_target, rate=0.1):\r\n","    super(Transformer, self).__init__()\r\n","\r\n","    self.tokenizer = Encoder(num_layers, d_model, num_heads, dff, \r\n","                           input_vocab_size, pe_input, rate)\r\n","\r\n","    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \r\n","                           target_vocab_size, pe_target, rate)\r\n","\r\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\r\n","\r\n","  def call(self, inp, tar, training, enc_padding_mask, \r\n","           look_ahead_mask, dec_padding_mask):\r\n","\r\n","    enc_output = self.tokenizer(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\r\n","\r\n","    # dec_output.shape == (batch_size, tar_seq_len, d_model)\r\n","    dec_output, attention_weights = self.decoder(\r\n","        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\r\n","\r\n","    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\r\n","\r\n","    return final_output, attention_weights\r\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNDXNdBwDw9T","executionInfo":{"status":"ok","timestamp":1613781760764,"user_tz":-60,"elapsed":36152,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"ff98615d-2d61-4859-bf84-ae7d9c26f9d7"},"source":["sample_transformer = Transformer(\r\n","    num_layers=2, d_model=512, num_heads=8, dff=2048, \r\n","    input_vocab_size=8500, target_vocab_size=8000, \r\n","    pe_input=10000, pe_target=6000)\r\n","\r\n","temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\r\n","temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\r\n","\r\n","fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \r\n","                               enc_padding_mask=None, \r\n","                               look_ahead_mask=None,\r\n","                               dec_padding_mask=None)\r\n","\r\n","fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 36, 8000])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"6R_oxgmYD1nb"},"source":["# Set Hyperparameters\r\n","\r\n","# The values for num_layers, d_model and dff were reduced in the project.\r\n","# The values used in the base model of transformer were ; num_layers = 6, d_model = 512, dff= 2048.\r\n","\r\n","num_layers = 4\r\n","d_model = 128\r\n","dff = 512\r\n","num_heads = 8\r\n","dropout_rate = 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sdew5QnEYXs"},"source":["# Optimizer learning schedule rate.\r\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n","  def __init__(self, d_model, warmup_steps=4000):\r\n","    super(CustomSchedule, self).__init__()\r\n","\r\n","    self.d_model = d_model\r\n","    self.d_model = tf.cast(self.d_model, tf.float32)\r\n","\r\n","    self.warmup_steps = warmup_steps\r\n","\r\n","  def __call__(self, step):\r\n","    arg1 = tf.math.rsqrt(step)\r\n","    arg2 = step * (self.warmup_steps ** -1.5)\r\n","\r\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SkmRmV8ECvNq"},"source":["learning_rate = CustomSchedule(d_model)\r\n","\r\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YfdaVwuvFiRY"},"source":["# Loss and metrics\r\n","#Apply padding mask when calculating the loss\r\n","\r\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3yNr4jsBF5Y-"},"source":["def loss_function(real, pred):\r\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\r\n","  loss_ = loss_object(real, pred)\r\n","\r\n","  mask = tf.cast(mask, dtype=loss_.dtype)\r\n","  loss_ *= mask\r\n","\r\n","  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\r\n","\r\n","\r\n","def accuracy_function(real, pred):\r\n","  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\r\n","\r\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\r\n","  accuracies = tf.math.logical_and(mask, accuracies)\r\n","\r\n","  accuracies = tf.cast(accuracies, dtype=tf.float32)\r\n","  mask = tf.cast(mask, dtype=tf.float32)\r\n","  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAw8_xzfGSh3"},"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\r\n","train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\r\n","\r\n","transformer = Transformer(\r\n","    num_layers=num_layers,\r\n","    d_model=d_model,\r\n","    num_heads=num_heads,\r\n","    dff=dff,\r\n","    input_vocab_size=tokenizers.pt.get_vocab_size(),\r\n","    target_vocab_size=tokenizers.en.get_vocab_size(), \r\n","    pe_input=1000, \r\n","    pe_target=1000,\r\n","    rate=dropout_rate)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UMMp4-z9G1cn","executionInfo":{"status":"ok","timestamp":1613781760781,"user_tz":-60,"elapsed":36109,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"d6450247-c648-4f49-8425-f985262e6f57"},"source":["x = tf.random.uniform((2,1,1,2), minval=1, maxval=3, dtype = tf.int32)\r\n","y = tf.random.uniform((2,2), minval=1, maxval=4, dtype=tf.int32)\r\n","\r\n","print(x)\r\n","print(y)\r\n","tf.math.maximum(x,y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[[[1 1]]]\n","\n","\n"," [[[2 2]]]], shape=(2, 1, 1, 2), dtype=int32)\n","tf.Tensor(\n","[[3 2]\n"," [1 3]], shape=(2, 2), dtype=int32)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2, 1, 2, 2), dtype=int32, numpy=\n","array([[[[3, 2],\n","         [1, 3]]],\n","\n","\n","       [[[3, 2],\n","         [2, 3]]]], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"02POBFLfIdH2"},"source":["def create_masks(inp, tar):\r\n","  # Encoder padding mask\r\n","  enc_padding_mask = create_padding_mask(inp)\r\n","\r\n","  # Used in the 2nd attention block in the decoder.\r\n","  # This padding mask is used to mask the encoder outputs.\r\n","  dec_padding_mask = create_padding_mask(inp)\r\n","\r\n","  # Used in the 1st attention block in the decoder.\r\n","  # It is used to pad and mask future tokens in the input received by \r\n","  # the decoder.\r\n","  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\r\n","  dec_target_padding_mask = create_padding_mask(tar)\r\n","  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\r\n","\r\n","  return enc_padding_mask, combined_mask, dec_padding_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"glC5EqfWKqdM"},"source":["checkpoint_path = './Checkpoints/translate/train'\r\n","\r\n","ckpt = tf.train.Checkpoint(transformer = transformer,\r\n","                           optimizer = optimizer)\r\n","\r\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\r\n","\r\n","if ckpt_manager.latest_checkpoint:\r\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\r\n","  print('Checkpoint Restored')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7crmS_67Ld-z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613781761278,"user_tz":-60,"elapsed":36575,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"3dd97bf6-c1cb-42b7-902d-cdc2aecae265"},"source":["EPOCHS = 20\r\n","transformer"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<__main__.Transformer at 0x7f327fa628d0>"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVPbaQjP1m3J","executionInfo":{"status":"ok","timestamp":1613781761279,"user_tz":-60,"elapsed":36559,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"dc1dcff4-59c1-4a45-8a85-19cb7c4cd7df"},"source":["ckpt_manager"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.checkpoint_management.CheckpointManager at 0x7f327f915400>"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"uNOihtpeNTsI"},"source":["# To avoid re-tracing due to the variable sequence lengths or variable batch sizes (the last batch is smaller), \r\n","# use input_signature to specify more generic shapes.\r\n","\r\n","train_step_signature = [\r\n","                        tf.TensorSpec(shape=(None, None), dtype=tf.int64),\r\n","                        tf.TensorSpec(shape=(None, None), dtype=tf.int64)\r\n","]\r\n","\r\n","@tf.function(input_signature = train_step_signature)\r\n","def train_step(inp, tar):\r\n","  tar_inp = tar[:, :-1]\r\n","  tar_real = tar[:, 1:]\r\n","\r\n","  enc_padding_mask , combined_mask , dec_padding_mask = create_masks(inp, tar_inp)\r\n","\r\n","  with tf.GradientTape() as tape:\r\n","    predictions, _  = transformer(inp, tar_inp,\r\n","                                   True,\r\n","                                   enc_padding_mask,\r\n","                                   combined_mask,\r\n","                                   dec_padding_mask)\r\n","    \r\n","    loss = loss_function(tar_real, predictions)\r\n","\r\n","    gradients = tape.gradient(loss, transformer.trainable_variables)\r\n","    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\r\n","\r\n","    train_loss(loss)\r\n","    train_accuracy(accuracy_function(tar_real, predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QiRX2oLZUj-N","outputId":"89fd957c-726c-4724-b1c6-48b6ace56c9d"},"source":["for epoch in range(EPOCHS):\r\n","  start = time.time()\r\n","  \r\n","  train_loss.reset_states()\r\n","  train_accuracy.reset_states()\r\n","\r\n","  # inp -> portugese, tar -> english\r\n","  for (batch, (inp, tar)) in enumerate(train_batches):\r\n","    train_step(inp, tar)\r\n","\r\n","    if batch % 50 == 0:\r\n","      print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\r\n","\r\n","  if (epoch + 1) % 4 == 0:\r\n","    ckpt_save_path = ckpt_manager.save()\r\n","    print(f'Saving checkpoint for epoch {epoch +1} at {ckpt_save_path}')\r\n","\r\n","  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\r\n","\r\n","  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\r\n","  # Training ineterrupted because of length of training."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 8.9047 Accuracy 0.0000\n","Epoch 1 Batch 50 Loss 8.8461 Accuracy 0.0003\n","Epoch 1 Batch 100 Loss 8.7310 Accuracy 0.0191\n","Epoch 1 Batch 150 Loss 8.6120 Accuracy 0.0288\n","Epoch 1 Batch 200 Loss 8.4690 Accuracy 0.0352\n","Epoch 1 Batch 250 Loss 8.2992 Accuracy 0.0412\n","Epoch 1 Batch 300 Loss 8.1073 Accuracy 0.0479\n","Epoch 1 Batch 350 Loss 7.9084 Accuracy 0.0537\n","Epoch 1 Batch 400 Loss 7.7201 Accuracy 0.0594\n","Epoch 1 Batch 450 Loss 7.5508 Accuracy 0.0664\n","Epoch 1 Batch 500 Loss 7.4036 Accuracy 0.0732\n","Epoch 1 Batch 550 Loss 7.2698 Accuracy 0.0804\n","Epoch 1 Batch 600 Loss 7.1458 Accuracy 0.0879\n","Epoch 1 Batch 650 Loss 7.0273 Accuracy 0.0955\n","Epoch 1 Batch 700 Loss 6.9201 Accuracy 0.1024\n","Epoch 1 Batch 750 Loss 6.8200 Accuracy 0.1086\n","Epoch 1 Batch 800 Loss 6.7245 Accuracy 0.1148\n","Epoch 1 Loss 6.7081 Accuracy 0.1158\n","Time taken for 1 epoch: 3317.37 secs\n","\n","Epoch 2 Batch 0 Loss 5.3143 Accuracy 0.1956\n","Epoch 2 Batch 50 Loss 5.2337 Accuracy 0.2112\n","Epoch 2 Batch 100 Loss 5.2044 Accuracy 0.2156\n","Epoch 2 Batch 150 Loss 5.1699 Accuracy 0.2202\n","Epoch 2 Batch 200 Loss 5.1449 Accuracy 0.2228\n","Epoch 2 Batch 250 Loss 5.1195 Accuracy 0.2253\n","Epoch 2 Batch 300 Loss 5.0951 Accuracy 0.2281\n","Epoch 2 Batch 350 Loss 5.0691 Accuracy 0.2308\n","Epoch 2 Batch 400 Loss 5.0462 Accuracy 0.2330\n","Epoch 2 Batch 450 Loss 5.0245 Accuracy 0.2347\n","Epoch 2 Batch 500 Loss 5.0063 Accuracy 0.2365\n","Epoch 2 Batch 550 Loss 4.9885 Accuracy 0.2380\n","Epoch 2 Batch 600 Loss 4.9709 Accuracy 0.2398\n","Epoch 2 Batch 650 Loss 4.9526 Accuracy 0.2413\n","Epoch 2 Batch 700 Loss 4.9337 Accuracy 0.2430\n","Epoch 2 Batch 750 Loss 4.9158 Accuracy 0.2445\n","Epoch 2 Batch 800 Loss 4.8995 Accuracy 0.2458\n","Epoch 2 Loss 4.8962 Accuracy 0.2461\n","Time taken for 1 epoch: 3170.70 secs\n","\n","Epoch 3 Batch 0 Loss 4.7491 Accuracy 0.2545\n","Epoch 3 Batch 50 Loss 4.5776 Accuracy 0.2721\n","Epoch 3 Batch 100 Loss 4.5634 Accuracy 0.2738\n","Epoch 3 Batch 150 Loss 4.5544 Accuracy 0.2753\n","Epoch 3 Batch 200 Loss 4.5464 Accuracy 0.2762\n","Epoch 3 Batch 250 Loss 4.5400 Accuracy 0.2766\n","Epoch 3 Batch 300 Loss 4.5339 Accuracy 0.2774\n","Epoch 3 Batch 350 Loss 4.5244 Accuracy 0.2780\n","Epoch 3 Batch 400 Loss 4.5131 Accuracy 0.2792\n","Epoch 3 Batch 450 Loss 4.4985 Accuracy 0.2811\n","Epoch 3 Batch 500 Loss 4.4837 Accuracy 0.2827\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Use-j5sBY742"},"source":["\r\n","transformer.save('./portugese_translator')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w28IRMmSH4te"},"source":[""],"execution_count":null,"outputs":[]}]}